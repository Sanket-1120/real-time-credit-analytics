{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc16c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# In: notebooks/02_training_data_preparation.ipynb\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add the project root to the Python path\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..') \n",
    "\n",
    "# Import your existing data fetcher functions\n",
    "from data_ingestion.yahoo_finance_fetcher import fetch_ticker_data\n",
    "from data_ingestion.news_fetcher import fetch_news_headlines\n",
    "from data_ingestion.fred_fetcher import fetch_macro_data\n",
    "\n",
    "# For sentiment analysis\n",
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "print(\"✅ Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ddf722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 1 year of stock data...\n",
      "Fetching data for tickers: ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'NVDA']...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Hack_proj\\notebooks\\..\\data_ingestion\\yahoo_finance_fetcher.py:21: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, period=period, interval=interval)\n",
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully.\n",
      "✅ Stock data fetched.\n",
      "Fetching 1 year of news data...\n",
      "Fetching news for query: 'AAPL company'...\n",
      "Successfully fetched 100 articles.\n",
      "Fetching news for query: 'MSFT company'...\n",
      "Successfully fetched 100 articles.\n",
      "Fetching news for query: 'GOOGL company'...\n",
      "Successfully fetched 100 articles.\n",
      "Fetching news for query: 'TSLA company'...\n",
      "Successfully fetched 100 articles.\n",
      "Fetching news for query: 'NVDA company'...\n",
      "Successfully fetched 100 articles.\n",
      "✅ News data fetched.\n",
      "Fetching FRED data...\n",
      "Successfully fetched macroeconomic data from FRED.\n",
      "✅ FRED data fetched.\n",
      "Performing sentiment and event analysis...\n",
      "✅ Sentiment and event analysis complete.\n",
      "Combining all data into a master DataFrame...\n",
      "✅ Master DataFrame created.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>positive_events</th>\n",
       "      <th>negative_events</th>\n",
       "      <th>GDP</th>\n",
       "      <th>CPI</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>BAMLH0A0HYM2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>225.460693</td>\n",
       "      <td>226.117640</td>\n",
       "      <td>224.405606</td>\n",
       "      <td>224.724131</td>\n",
       "      <td>30299000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30331.117</td>\n",
       "      <td>322.132</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>225.351212</td>\n",
       "      <td>226.923894</td>\n",
       "      <td>224.007474</td>\n",
       "      <td>225.470666</td>\n",
       "      <td>34765500</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30331.117</td>\n",
       "      <td>322.132</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>223.489868</td>\n",
       "      <td>227.282216</td>\n",
       "      <td>222.862782</td>\n",
       "      <td>226.734761</td>\n",
       "      <td>43695300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30331.117</td>\n",
       "      <td>322.132</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>225.789169</td>\n",
       "      <td>227.162781</td>\n",
       "      <td>223.290802</td>\n",
       "      <td>224.614643</td>\n",
       "      <td>38677300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30331.117</td>\n",
       "      <td>322.132</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>226.127594</td>\n",
       "      <td>226.227137</td>\n",
       "      <td>222.852841</td>\n",
       "      <td>225.709541</td>\n",
       "      <td>30602200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30331.117</td>\n",
       "      <td>322.132</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       Close        High         Low        Open    Volume ticker  \\\n",
       "0 2024-08-20  225.460693  226.117640  224.405606  224.724131  30299000   AAPL   \n",
       "1 2024-08-21  225.351212  226.923894  224.007474  225.470666  34765500   AAPL   \n",
       "2 2024-08-22  223.489868  227.282216  222.862782  226.734761  43695300   AAPL   \n",
       "3 2024-08-23  225.789169  227.162781  223.290802  224.614643  38677300   AAPL   \n",
       "4 2024-08-26  226.127594  226.227137  222.852841  225.709541  30602200   AAPL   \n",
       "\n",
       "   sentiment  positive_events  negative_events        GDP      CPI  FEDFUNDS  \\\n",
       "0        0.0              0.0              0.0  30331.117  322.132      4.33   \n",
       "1        0.0              0.0              0.0  30331.117  322.132      4.33   \n",
       "2        0.0              0.0              0.0  30331.117  322.132      4.33   \n",
       "3        0.0              0.0              0.0  30331.117  322.132      4.33   \n",
       "4        0.0              0.0              0.0  30331.117  322.132      4.33   \n",
       "\n",
       "   UNRATE  BAMLH0A0HYM2  \n",
       "0     4.2          2.88  \n",
       "1     4.2          2.88  \n",
       "2     4.2          2.88  \n",
       "3     4.2          2.88  \n",
       "4     4.2          2.88  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Cell 2 of your notebook\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'NVDA']\n",
    "END_DATE = datetime.now()\n",
    "START_DATE = END_DATE - timedelta(days=365)\n",
    "\n",
    "# --- 1. FETCH RAW DATA ---\n",
    "print(\"Fetching 1 year of stock data...\")\n",
    "stock_df = fetch_ticker_data(TICKERS, period=\"1y\")\n",
    "if isinstance(stock_df.columns, pd.MultiIndex):\n",
    "    stock_df.columns = ['_'.join(col).strip() for col in stock_df.columns.values]\n",
    "stock_df.index = pd.to_datetime(stock_df.index).tz_localize(None)\n",
    "print(\"✅ Stock data fetched.\")\n",
    "\n",
    "print(\"Fetching 1 year of news data...\")\n",
    "all_news = []\n",
    "for ticker in TICKERS:\n",
    "    news = fetch_news_headlines(query=f\"{ticker} company\", page_size=100)\n",
    "    news['ticker'] = ticker\n",
    "    all_news.append(news)\n",
    "news_df = pd.concat(all_news, ignore_index=True)\n",
    "news_df['publishedAt'] = pd.to_datetime(news_df['publishedAt']).dt.tz_localize(None)\n",
    "print(\"✅ News data fetched.\")\n",
    "\n",
    "print(\"Fetching FRED data...\")\n",
    "macro_data_dict = fetch_macro_data()\n",
    "print(\"✅ FRED data fetched.\")\n",
    "\n",
    "# --- 2. ENGINEER SENTIMENT & EVENT FEATURES ---\n",
    "print(\"Performing sentiment and event analysis...\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define keywords for event classification\n",
    "NEGATIVE_KEYWORDS = ['layoffs', 'debt', 'downgrade', 'lawsuit', 'investigation', 'recall', 'outage', 'cuts', 'fine']\n",
    "POSITIVE_KEYWORDS = ['expansion', 'profit', 'upgrade', 'hiring', 'record', 'partnership', 'launch', 'beats', 'growth']\n",
    "\n",
    "def analyze_headline(headline):\n",
    "    \"\"\"Analyzes a headline for sentiment and event type.\"\"\"\n",
    "    sentiment = analyzer.polarity_scores(headline)['compound']\n",
    "    event_type = 'Neutral'\n",
    "    if any(kw in headline.lower() for kw in NEGATIVE_KEYWORDS):\n",
    "        event_type = 'Negative Event'\n",
    "    elif any(kw in headline.lower() for kw in POSITIVE_KEYWORDS):\n",
    "        event_type = 'Positive Event'\n",
    "    return sentiment, event_type\n",
    "\n",
    "# Apply the new analysis function\n",
    "news_df[['sentiment', 'event_type']] = news_df['title'].apply(analyze_headline).apply(pd.Series)\n",
    "\n",
    "news_df['date'] = news_df['publishedAt'].dt.date\n",
    "# Create daily aggregations for both sentiment and events\n",
    "daily_features = news_df.groupby(['ticker', 'date']).agg(\n",
    "    sentiment=('sentiment', 'mean'),\n",
    "    positive_events=('event_type', lambda x: (x == 'Positive Event').sum()),\n",
    "    negative_events=('event_type', lambda x: (x == 'Negative Event').sum())\n",
    ").reset_index()\n",
    "daily_features['date'] = pd.to_datetime(daily_features['date'])\n",
    "print(\"✅ Sentiment and event analysis complete.\")\n",
    "\n",
    "# --- 3. COMBINE INTO MASTER DATAFRAME ---\n",
    "print(\"Combining all data into a master DataFrame...\")\n",
    "master_df_list = []\n",
    "for ticker in TICKERS:\n",
    "    ticker_stock_df = stock_df[[col for col in stock_df.columns if ticker in col]].copy()\n",
    "    ticker_stock_df.columns = [col.replace(f\"_{ticker}\", \"\") for col in ticker_stock_df.columns]\n",
    "    ticker_stock_df['ticker'] = ticker\n",
    "    ticker_stock_df.reset_index(inplace=True)\n",
    "    ticker_stock_df.rename(columns={'index': 'date', 'Date': 'date'}, inplace=True)\n",
    "    \n",
    "    ticker_daily_features = daily_features[daily_features['ticker'] == ticker]\n",
    "    \n",
    "    merged_df = pd.merge(ticker_stock_df, ticker_daily_features, on=['date', 'ticker'], how='left')\n",
    "    master_df_list.append(merged_df)\n",
    "\n",
    "final_df = pd.concat(master_df_list, ignore_index=True)\n",
    "\n",
    "if macro_data_dict:\n",
    "    for series_name, value in macro_data_dict.items():\n",
    "        final_df[series_name] = value\n",
    "\n",
    "# Fill missing values for days with no news/events\n",
    "final_df[['sentiment', 'positive_events', 'negative_events']] = final_df[['sentiment', 'positive_events', 'negative_events']].fillna(0)\n",
    "print(\"✅ Master DataFrame created.\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a64208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final training dataset with 1250 rows saved to '../training_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the final dataset to a CSV file in the project's root directory\n",
    "output_path = '../training_dataset.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Final training dataset with {len(final_df)} rows saved to '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c7f04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 headlines classified as significant events:\n",
      "    ticker      event_type                                              title\n",
      "11    AAPL  Positive Event  Direxion Daily AAPL Bull 2X Shares (NASDAQ:AAP...\n",
      "19    AAPL  Positive Event  Foxconn’s Apple era fades as AI servers drive ...\n",
      "59    AAPL  Negative Event  AAPL INVESTOR ALERT: Bronstein, Gewirtz & Gros...\n",
      "75    AAPL  Negative Event  Pacific Wealth Strategies Group Inc. Cuts Posi...\n",
      "95    AAPL  Negative Event  Bay Capital Advisors LLC Cuts Stock Position i...\n",
      "98    AAPL  Positive Event  Stock market today: Dow jumps 450 points as S&...\n",
      "141   MSFT  Negative Event  Coastline Trust Co Cuts Stock Position in Micr...\n",
      "192   MSFT  Positive Event  Stock market today: Dow jumps 450 points as S&...\n",
      "226  GOOGL  Positive Event  Why This 1 Growth Stock Could Be a Great Addit...\n",
      "254  GOOGL  Negative Event  Maryland State Retirement & Pension System Cut...\n",
      "281  GOOGL  Positive Event  Big Tech is driving the stock market to new re...\n",
      "298  GOOGL  Positive Event  Alphabet (GOOGL): LivePerson Announces Signifi...\n",
      "299  GOOGL  Negative Event  Halter Ferguson Financial Inc. Cuts Stake in A...\n",
      "310   TSLA  Negative Event  The Gross Law Firm Reminds Tesla, Inc. Investo...\n",
      "342   TSLA  Negative Event  Levi & Korsinsky Reminds Shareholders of a Lea...\n",
      "347   TSLA  Positive Event  Stock market today: Dow jumps 450 points as S&...\n",
      "360   TSLA  Positive Event  Big Tech is driving the stock market to new re...\n",
      "363   TSLA  Negative Event  Tesla, industry price cuts boost EV sales in J...\n",
      "371   TSLA  Positive Event  Leverage Shares by Themes Expands Leverage Sin...\n",
      "393   TSLA  Positive Event  Stock market today: Nasdaq hits fresh record, ...\n",
      "407   NVDA  Positive Event                 VanEck announce new growth ASX ETF\n",
      "430   NVDA  Positive Event  Foxconn’s Apple era fades as AI servers drive ...\n",
      "478   NVDA  Positive Event  Stock market today: Dow eyes record on UnitedH...\n"
     ]
    }
   ],
   "source": [
    "# In a new cell in your notebook\n",
    "\n",
    "# Filter the DataFrame to find all rows where an event was detected\n",
    "detected_events_df = news_df[news_df['event_type'] != 'Neutral']\n",
    "\n",
    "if not detected_events_df.empty:\n",
    "    print(f\"Found {len(detected_events_df)} headlines classified as significant events:\")\n",
    "    # Display the ticker, event type, and the headline text\n",
    "    print(detected_events_df[['ticker', 'event_type', 'title']])\n",
    "else:\n",
    "    print(\"No significant positive or negative events found in the fetched headlines.\")\n",
    "    print(\"This is normal if there was no major news for the selected tickers in the last month.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAYA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
